#!/usr/bin/env python3
"""
BigQuery ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆã—ã€ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’æŒ¿å…¥ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ä»¥ä¸‹ã‚’å®Ÿè¡Œã—ã¾ã™:
1. BigQuery ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä½œæˆ
2. ç‰¹å¾´ãƒ‡ãƒ¼ã‚¿ç”¨ãƒ†ãƒ¼ãƒ–ãƒ«ã®ä½œæˆ
3. ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®æŒ¿å…¥

Requires: Python 3.11+
"""

import sys
from datetime import datetime, timezone
from pathlib import Path
from typing import Any

import numpy as np
import pandas as pd
import yaml
from google.cloud import bigquery
from google.cloud.exceptions import Conflict


def load_config() -> dict[str, Any]:
    """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
    config_path = Path(__file__).parent.parent / "config" / "config.yaml"
    with open(config_path, "r", encoding="utf-8") as f:
        return yaml.safe_load(f)


def generate_sample_data(config: dict[str, Any], use_drifted: bool = False) -> pd.DataFrame:
    """
    ã‚µãƒ³ãƒ—ãƒ«ç‰¹å¾´ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹

    Args:
        config: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹
        use_drifted: True ã®å ´åˆã€ãƒ‰ãƒªãƒ•ãƒˆå¾Œã®ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒã‚’ä½¿ç”¨

    Returns:
        ç”Ÿæˆã•ã‚ŒãŸã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã® DataFrame
    """
    num_records = config["sample_data"]["num_records"]
    data_config = config["sample_data"]["drifted" if use_drifted else "initial"]

    np.random.seed(42 if not use_drifted else 123)

    # ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ ID ã‚’ç”Ÿæˆ
    entity_ids = [f"user_{i:04d}" for i in range(num_records)]

    # æ•°å€¤ç‰¹å¾´ã‚’ç”Ÿæˆ
    ages = np.random.normal(
        data_config["age_mean"], data_config["age_std"], num_records
    )
    ages = np.clip(ages, 18, 80).astype(int)  # 18-80æ­³ã®ç¯„å›²ã«åˆ¶é™

    incomes = np.random.normal(
        data_config["income_mean"], data_config["income_std"], num_records
    )
    incomes = np.clip(incomes, 20000, 200000)  # åå…¥ã®ç¯„å›²ã‚’åˆ¶é™

    # ã‚«ãƒ†ã‚´ãƒªç‰¹å¾´ã‚’ç”Ÿæˆ
    categories = np.random.choice(
        data_config["categories"],
        size=num_records,
        p=data_config["category_weights"],
    )

    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ç”Ÿæˆ
    timestamp = datetime.now(timezone.utc)

    df = pd.DataFrame(
        {
            "entity_id": entity_ids,
            "age": ages,
            "income": incomes,
            "category": categories,
            "feature_timestamp": [timestamp] * num_records,
        }
    )

    return df


def create_dataset(
    client: bigquery.Client, project_id: str, dataset_id: str, location: str
) -> None:
    """BigQuery ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆã™ã‚‹"""
    dataset_ref = f"{project_id}.{dataset_id}"

    dataset = bigquery.Dataset(dataset_ref)
    dataset.location = location
    dataset.description = "Vertex AI Feature Store ã‚µãƒ³ãƒ—ãƒ«ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ"

    try:
        client.create_dataset(dataset)
        print(f"âœ… ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ '{dataset_ref}' ã‚’ä½œæˆã—ã¾ã—ãŸ")
    except Conflict:
        print(f"â„¹ï¸  ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ '{dataset_ref}' ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™")


def create_table(
    client: bigquery.Client, project_id: str, dataset_id: str, table_id: str
) -> None:
    """BigQuery ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆã™ã‚‹"""
    table_ref = f"{project_id}.{dataset_id}.{table_id}"

    schema = [
        bigquery.SchemaField("entity_id", "STRING", mode="REQUIRED"),
        bigquery.SchemaField("age", "INT64", mode="NULLABLE"),
        bigquery.SchemaField("income", "FLOAT64", mode="NULLABLE"),
        bigquery.SchemaField("category", "STRING", mode="NULLABLE"),
        bigquery.SchemaField("feature_timestamp", "TIMESTAMP", mode="REQUIRED"),
    ]

    table = bigquery.Table(table_ref, schema=schema)
    table.description = "ãƒ¦ãƒ¼ã‚¶ãƒ¼ç‰¹å¾´ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆFeature Monitoring ã‚µãƒ³ãƒ—ãƒ«ç”¨ï¼‰"

    try:
        client.create_table(table)
        print(f"âœ… ãƒ†ãƒ¼ãƒ–ãƒ« '{table_ref}' ã‚’ä½œæˆã—ã¾ã—ãŸ")
    except Conflict:
        print(f"â„¹ï¸  ãƒ†ãƒ¼ãƒ–ãƒ« '{table_ref}' ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã—ã¦å†ä½œæˆã—ã¾ã™...")
        # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤
        query = f"DELETE FROM `{table_ref}` WHERE TRUE"
        client.query(query).result()
        print(f"âœ… ãƒ†ãƒ¼ãƒ–ãƒ« '{table_ref}' ã®ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")


def insert_data(
    client: bigquery.Client,
    project_id: str,
    dataset_id: str,
    table_id: str,
    df: pd.DataFrame,
) -> None:
    """DataFrame ã®ãƒ‡ãƒ¼ã‚¿ã‚’ BigQuery ãƒ†ãƒ¼ãƒ–ãƒ«ã«æŒ¿å…¥ã™ã‚‹"""
    table_ref = f"{project_id}.{dataset_id}.{table_id}"

    job_config = bigquery.LoadJobConfig(
        write_disposition=bigquery.WriteDisposition.WRITE_APPEND,
    )

    job = client.load_table_from_dataframe(df, table_ref, job_config=job_config)
    job.result()  # ã‚¸ãƒ§ãƒ–ã®å®Œäº†ã‚’å¾…æ©Ÿ

    print(f"âœ… {len(df)} ä»¶ã®ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’ '{table_ref}' ã«æŒ¿å…¥ã—ã¾ã—ãŸ")


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("=" * 60)
    print("BigQuery ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ»ãƒ†ãƒ¼ãƒ–ãƒ« ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—")
    print("=" * 60)

    # è¨­å®šã‚’èª­ã¿è¾¼ã‚€
    config = load_config()
    project_id = config["project_id"]
    location = config["location"]
    dataset_id = config["bigquery"]["dataset_id"]
    table_id = config["bigquery"]["table_id"]

    if project_id == "your-project-id":
        print("âŒ ã‚¨ãƒ©ãƒ¼: config/config.yaml ã® project_id ã‚’è¨­å®šã—ã¦ãã ã•ã„")
        sys.exit(1)

    print(f"\nãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {project_id}")
    print(f"ãƒªãƒ¼ã‚¸ãƒ§ãƒ³: {location}")
    print(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: {dataset_id}")
    print(f"ãƒ†ãƒ¼ãƒ–ãƒ«: {table_id}")

    # BigQuery ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆ
    client = bigquery.Client(project=project_id)

    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆ
    print("\nğŸ“ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆä¸­...")
    create_dataset(client, project_id, dataset_id, location)

    # ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆ
    print("\nğŸ“‹ ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆä¸­...")
    create_table(client, project_id, dataset_id, table_id)

    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¦æŒ¿å…¥
    print("\nğŸ“Š ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆãƒ»æŒ¿å…¥ä¸­...")
    df = generate_sample_data(config, use_drifted=False)
    insert_data(client, project_id, dataset_id, table_id, df)

    # ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
    print("\nğŸ“ˆ æŒ¿å…¥ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆæƒ…å ±:")
    print(f"  - ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(df)}")
    print(f"  - å¹´é½¢: å¹³å‡ {df['age'].mean():.1f}, æ¨™æº–åå·® {df['age'].std():.1f}")
    print(f"  - åå…¥: å¹³å‡ {df['income'].mean():.0f}, æ¨™æº–åå·® {df['income'].std():.0f}")
    print(f"  - ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒ: {df['category'].value_counts().to_dict()}")

    print("\n" + "=" * 60)
    print("âœ… BigQuery ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãŒå®Œäº†ã—ã¾ã—ãŸ")
    print("=" * 60)
    print("\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—: python setup/02_create_feature_group.py ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")


if __name__ == "__main__":
    main()
