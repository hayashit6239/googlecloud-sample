#!/usr/bin/env python3
"""
ç‰¹å¾´é‡çµ±è¨ˆæƒ…å ±ã‚’å–å¾—ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ BigQuery ã® ML.TFDV_VALIDATE é–¢æ•°ã‚’ä½¿ç”¨ã—ã¦
ç‰¹å¾´é‡ã®çµ±è¨ˆæƒ…å ±ã¨ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡ºã‚’è¡Œã„ã¾ã™ã€‚

Requires: Python 3.11+
"""

import argparse
import sys
from pathlib import Path
from typing import Any

import pandas as pd
from google.cloud import bigquery

# å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
sys.path.insert(0, str(Path(__file__).parent.parent))
from utils.config import load_config


def get_basic_stats(
    client: bigquery.Client,
    project_id: str,
    dataset_id: str,
    table_id: str,
) -> pd.DataFrame:
    """åŸºæœ¬çš„ãªçµ±è¨ˆæƒ…å ±ã‚’å–å¾—ã™ã‚‹"""
    query = f"""
    SELECT
        COUNT(*) as total_records,
        AVG(age) as avg_age,
        STDDEV(age) as std_age,
        MIN(age) as min_age,
        MAX(age) as max_age,
        AVG(income) as avg_income,
        STDDEV(income) as std_income,
        MIN(income) as min_income,
        MAX(income) as max_income
    FROM `{project_id}.{dataset_id}.{table_id}`
    """

    return client.query(query).to_dataframe()


def get_category_distribution(
    client: bigquery.Client,
    project_id: str,
    dataset_id: str,
    table_id: str,
) -> pd.DataFrame:
    """ã‚«ãƒ†ã‚´ãƒªã®åˆ†å¸ƒã‚’å–å¾—ã™ã‚‹"""
    query = f"""
    SELECT
        category,
        COUNT(*) as count,
        ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER(), 2) as percentage
    FROM `{project_id}.{dataset_id}.{table_id}`
    GROUP BY category
    ORDER BY count DESC
    """

    return client.query(query).to_dataframe()


def get_time_series_stats(
    client: bigquery.Client,
    project_id: str,
    dataset_id: str,
    table_id: str,
) -> pd.DataFrame:
    """æ™‚ç³»åˆ—ã§ã®çµ±è¨ˆæƒ…å ±ã‚’å–å¾—ã™ã‚‹"""
    query = f"""
    SELECT
        DATE(feature_timestamp) as date,
        COUNT(*) as record_count,
        AVG(age) as avg_age,
        AVG(income) as avg_income
    FROM `{project_id}.{dataset_id}.{table_id}`
    GROUP BY date
    ORDER BY date DESC
    LIMIT 10
    """

    return client.query(query).to_dataframe()


def detect_drift_with_tfdv(
    client: bigquery.Client,
    project_id: str,
    dataset_id: str,
    table_id: str,
    baseline_query: str,
    current_query: str,
) -> pd.DataFrame | None:
    """
    ML.TFDV_VALIDATE ã‚’ä½¿ç”¨ã—ã¦ãƒ‰ãƒªãƒ•ãƒˆã‚’æ¤œå‡ºã™ã‚‹

    æ³¨æ„: ã“ã®æ©Ÿèƒ½ã¯ BigQuery ML ãŒæœ‰åŠ¹ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã®ã¿å‹•ä½œã—ã¾ã™
    """
    # TFDV ã‚’ä½¿ç”¨ã—ãŸãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡ºã‚¯ã‚¨ãƒª
    query = f"""
    SELECT
        feature_name,
        anomaly_short_description,
        anomaly_long_description
    FROM ML.TFDV_VALIDATE(
        (SELECT * FROM ({baseline_query})),
        (SELECT * FROM ({current_query})),
        STRUCT(0.3 AS drift_threshold)
    )
    """

    try:
        return client.query(query).to_dataframe()
    except Exception as e:
        print(f"âš ï¸  TFDV æ¤œè¨¼ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    parser = argparse.ArgumentParser(
        description="ç‰¹å¾´é‡çµ±è¨ˆæƒ…å ±ã‚’å–å¾—ã™ã‚‹"
    )
    parser.add_argument(
        "--detailed",
        action="store_true",
        help="è©³ç´°ãªçµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º",
    )
    args = parser.parse_args()

    print("=" * 60)
    print("ç‰¹å¾´é‡çµ±è¨ˆæƒ…å ±")
    print("=" * 60)

    # è¨­å®šã‚’èª­ã¿è¾¼ã‚€
    config = load_config()
    project_id = config["project_id"]
    dataset_id = config["bigquery"]["dataset_id"]
    table_id = config["bigquery"]["table_id"]

    if project_id == "your-project-id":
        print("âŒ ã‚¨ãƒ©ãƒ¼: vertexai-mlops/config.yaml ã® project_id ã‚’è¨­å®šã—ã¦ãã ã•ã„")
        sys.exit(1)

    print(f"\nãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {project_id}")
    print(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: {dataset_id}")
    print(f"ãƒ†ãƒ¼ãƒ–ãƒ«: {table_id}")

    # BigQuery ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆ
    client = bigquery.Client(project=project_id)

    # åŸºæœ¬çµ±è¨ˆæƒ…å ±ã‚’å–å¾—
    print("\nğŸ“Š åŸºæœ¬çµ±è¨ˆæƒ…å ±ã‚’å–å¾—ä¸­...")
    basic_stats = get_basic_stats(client, project_id, dataset_id, table_id)

    print("\n" + "=" * 40)
    print("æ•°å€¤ç‰¹å¾´é‡ã®çµ±è¨ˆ")
    print("=" * 40)
    print(f"ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {int(basic_stats['total_records'].iloc[0])}")
    print(f"\nã€å¹´é½¢ (age)ã€‘")
    print(f"  å¹³å‡: {basic_stats['avg_age'].iloc[0]:.1f}")
    print(f"  æ¨™æº–åå·®: {basic_stats['std_age'].iloc[0]:.1f}")
    print(f"  æœ€å°: {int(basic_stats['min_age'].iloc[0])}")
    print(f"  æœ€å¤§: {int(basic_stats['max_age'].iloc[0])}")

    print(f"\nã€åå…¥ (income)ã€‘")
    print(f"  å¹³å‡: {basic_stats['avg_income'].iloc[0]:,.0f}")
    print(f"  æ¨™æº–åå·®: {basic_stats['std_income'].iloc[0]:,.0f}")
    print(f"  æœ€å°: {basic_stats['min_income'].iloc[0]:,.0f}")
    print(f"  æœ€å¤§: {basic_stats['max_income'].iloc[0]:,.0f}")

    # ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒã‚’å–å¾—
    print("\n" + "=" * 40)
    print("ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒ")
    print("=" * 40)
    category_dist = get_category_distribution(client, project_id, dataset_id, table_id)
    for _, row in category_dist.iterrows():
        bar = "â–ˆ" * int(row["percentage"] / 5)
        print(f"  {row['category']}: {row['count']} ({row['percentage']}%) {bar}")

    if args.detailed:
        # æ™‚ç³»åˆ—çµ±è¨ˆã‚’å–å¾—
        print("\n" + "=" * 40)
        print("æ™‚ç³»åˆ—çµ±è¨ˆï¼ˆç›´è¿‘10æ—¥ï¼‰")
        print("=" * 40)
        time_stats = get_time_series_stats(client, project_id, dataset_id, table_id)
        if not time_stats.empty:
            for _, row in time_stats.iterrows():
                print(
                    f"  {row['date']}: "
                    f"ä»¶æ•°={int(row['record_count'])}, "
                    f"å¹³å‡å¹´é½¢={row['avg_age']:.1f}, "
                    f"å¹³å‡åå…¥={row['avg_income']:,.0f}"
                )
        else:
            print("  ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")

    print("\n" + "=" * 60)
    print("âœ… å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ")
    print("=" * 60)
    print("\nğŸ’¡ ãƒ’ãƒ³ãƒˆ:")
    print("  - ãƒ‰ãƒªãƒ•ãƒˆã‚’æ¤œå‡ºã™ã‚‹ã«ã¯: python simulation/simulate_drift.py ã‚’å®Ÿè¡Œ")
    print("  - ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã‚¸ãƒ§ãƒ–: python monitoring/run_monitor_job.py ã‚’å®Ÿè¡Œ")


if __name__ == "__main__":
    main()
