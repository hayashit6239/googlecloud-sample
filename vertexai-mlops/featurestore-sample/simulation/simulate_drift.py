#!/usr/bin/env python3
"""
ç‰¹å¾´é‡ãƒ‰ãƒªãƒ•ãƒˆã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ä»¥ä¸‹ã‚’å®Ÿè¡Œã—ã¾ã™:
1. ãƒ‰ãƒªãƒ•ãƒˆã—ãŸãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆï¼ˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã® drifted è¨­å®šã‚’ä½¿ç”¨ï¼‰
2. BigQuery ãƒ†ãƒ¼ãƒ–ãƒ«ã¸ã®ãƒ‡ãƒ¼ã‚¿è¿½åŠ 
3. ãƒ‰ãƒªãƒ•ãƒˆå‰å¾Œã®ãƒ‡ãƒ¼ã‚¿æ¯”è¼ƒ

Requires: Python 3.11+
"""

import argparse
import sys
from datetime import datetime, timezone
from pathlib import Path
from typing import Any

import numpy as np
import pandas as pd
from google.cloud import bigquery

# å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
sys.path.insert(0, str(Path(__file__).parent.parent))
from utils.config import load_config


def generate_drifted_data(config: dict[str, Any]) -> pd.DataFrame:
    """
    ãƒ‰ãƒªãƒ•ãƒˆã—ãŸã‚µãƒ³ãƒ—ãƒ«ç‰¹å¾´ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹

    Args:
        config: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹

    Returns:
        ç”Ÿæˆã•ã‚ŒãŸãƒ‰ãƒªãƒ•ãƒˆãƒ‡ãƒ¼ã‚¿ã® DataFrame
    """
    num_records = config["sample_data"]["num_records"]
    data_config = config["sample_data"]["drifted"]

    np.random.seed(123)

    # æ–°ã—ã„ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ ID ã‚’ç”Ÿæˆï¼ˆæ—¢å­˜ã¨é‡è¤‡ã—ãªã„ã‚ˆã†ã«ï¼‰
    start_id = num_records
    entity_ids = [f"user_{i:04d}" for i in range(start_id, start_id + num_records)]

    # ãƒ‰ãƒªãƒ•ãƒˆã—ãŸæ•°å€¤ç‰¹å¾´ã‚’ç”Ÿæˆ
    ages = np.random.normal(
        data_config["age_mean"], data_config["age_std"], num_records
    )
    ages = np.clip(ages, 18, 80).astype(int)

    incomes = np.random.normal(
        data_config["income_mean"], data_config["income_std"], num_records
    )
    incomes = np.clip(incomes, 20000, 200000)

    # ãƒ‰ãƒªãƒ•ãƒˆã—ãŸã‚«ãƒ†ã‚´ãƒªç‰¹å¾´ã‚’ç”Ÿæˆ
    categories = np.random.choice(
        data_config["categories"],
        size=num_records,
        p=data_config["category_weights"],
    )

    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ç”Ÿæˆ
    timestamp = datetime.now(timezone.utc)

    df = pd.DataFrame(
        {
            "entity_id": entity_ids,
            "age": ages,
            "income": incomes,
            "category": categories,
            "feature_timestamp": [timestamp] * num_records,
        }
    )

    return df


def get_existing_stats(
    client: bigquery.Client,
    project_id: str,
    dataset_id: str,
    table_id: str,
) -> dict[str, Any]:
    """æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆæƒ…å ±ã‚’å–å¾—ã™ã‚‹"""
    query = f"""
    SELECT
        COUNT(*) as total_records,
        AVG(age) as avg_age,
        STDDEV(age) as std_age,
        AVG(income) as avg_income,
        STDDEV(income) as std_income
    FROM `{project_id}.{dataset_id}.{table_id}`
    """

    result = client.query(query).to_dataframe()
    return result.iloc[0].to_dict()


def get_category_distribution(
    client: bigquery.Client,
    project_id: str,
    dataset_id: str,
    table_id: str,
) -> pd.DataFrame:
    """ã‚«ãƒ†ã‚´ãƒªã®åˆ†å¸ƒã‚’å–å¾—ã™ã‚‹"""
    query = f"""
    SELECT
        category,
        COUNT(*) as count
    FROM `{project_id}.{dataset_id}.{table_id}`
    GROUP BY category
    ORDER BY category
    """

    return client.query(query).to_dataframe()


def insert_data(
    client: bigquery.Client,
    project_id: str,
    dataset_id: str,
    table_id: str,
    df: pd.DataFrame,
) -> None:
    """DataFrame ã®ãƒ‡ãƒ¼ã‚¿ã‚’ BigQuery ãƒ†ãƒ¼ãƒ–ãƒ«ã«æŒ¿å…¥ã™ã‚‹"""
    table_ref = f"{project_id}.{dataset_id}.{table_id}"

    job_config = bigquery.LoadJobConfig(
        write_disposition=bigquery.WriteDisposition.WRITE_APPEND,
    )

    job = client.load_table_from_dataframe(df, table_ref, job_config=job_config)
    job.result()


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    parser = argparse.ArgumentParser(
        description="ç‰¹å¾´é‡ãƒ‰ãƒªãƒ•ãƒˆã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã™ã‚‹"
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="ãƒ‡ãƒ¼ã‚¿ã‚’æŒ¿å…¥ã›ãšã«ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœã®ã¿è¡¨ç¤º",
    )
    args = parser.parse_args()

    print("=" * 60)
    print("ç‰¹å¾´é‡ãƒ‰ãƒªãƒ•ãƒˆ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
    print("=" * 60)

    # è¨­å®šã‚’èª­ã¿è¾¼ã‚€
    config = load_config()
    project_id = config["project_id"]
    dataset_id = config["bigquery"]["dataset_id"]
    table_id = config["bigquery"]["table_id"]

    if project_id == "your-project-id":
        print("âŒ ã‚¨ãƒ©ãƒ¼: vertexai-mlops/config.yaml ã® project_id ã‚’è¨­å®šã—ã¦ãã ã•ã„")
        sys.exit(1)

    print(f"\nãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {project_id}")
    print(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: {dataset_id}")
    print(f"ãƒ†ãƒ¼ãƒ–ãƒ«: {table_id}")

    # BigQuery ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆ
    client = bigquery.Client(project=project_id)

    # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆã‚’å–å¾—
    print("\nğŸ“Š æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆæƒ…å ±ã‚’å–å¾—ä¸­...")
    existing_stats = get_existing_stats(client, project_id, dataset_id, table_id)
    existing_categories = get_category_distribution(client, project_id, dataset_id, table_id)

    print("\nã€ãƒ‰ãƒªãƒ•ãƒˆå‰ã®ãƒ‡ãƒ¼ã‚¿ã€‘")
    print(f"  ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {int(existing_stats['total_records'])}")
    print(f"  å¹´é½¢: å¹³å‡ {existing_stats['avg_age']:.1f}, æ¨™æº–åå·® {existing_stats['std_age']:.1f}")
    print(f"  åå…¥: å¹³å‡ {existing_stats['avg_income']:,.0f}, æ¨™æº–åå·® {existing_stats['std_income']:,.0f}")
    print(f"  ã‚«ãƒ†ã‚´ãƒª: {dict(zip(existing_categories['category'], existing_categories['count']))}")

    # ãƒ‰ãƒªãƒ•ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
    print("\nğŸ“ˆ ãƒ‰ãƒªãƒ•ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆä¸­...")
    drifted_df = generate_drifted_data(config)

    print("\nã€ãƒ‰ãƒªãƒ•ãƒˆå¾Œã®ãƒ‡ãƒ¼ã‚¿ï¼ˆæ–°è¦ç”Ÿæˆåˆ†ï¼‰ã€‘")
    print(f"  ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(drifted_df)}")
    print(f"  å¹´é½¢: å¹³å‡ {drifted_df['age'].mean():.1f}, æ¨™æº–åå·® {drifted_df['age'].std():.1f}")
    print(f"  åå…¥: å¹³å‡ {drifted_df['income'].mean():,.0f}, æ¨™æº–åå·® {drifted_df['income'].std():,.0f}")
    print(f"  ã‚«ãƒ†ã‚´ãƒª: {drifted_df['category'].value_counts().to_dict()}")

    # ãƒ‰ãƒªãƒ•ãƒˆã®å·®åˆ†ã‚’è¨ˆç®—
    print("\n" + "=" * 40)
    print("ğŸ“‰ ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡ºï¼ˆäºˆæ¸¬ï¼‰")
    print("=" * 40)

    initial_config = config["sample_data"]["initial"]
    drifted_config = config["sample_data"]["drifted"]

    age_drift = abs(drifted_config["age_mean"] - initial_config["age_mean"]) / initial_config["age_std"]
    income_drift = abs(drifted_config["income_mean"] - initial_config["income_mean"]) / initial_config["income_std"]

    drift_threshold = config["feature_store"]["features"][0]["drift_threshold"]

    print(f"\n  å¹´é½¢ãƒ‰ãƒªãƒ•ãƒˆï¼ˆæ­£è¦åŒ–ï¼‰: {age_drift:.2f}")
    print(f"    â†’ é–¾å€¤ {drift_threshold} ã¨ã®æ¯”è¼ƒ: {'ğŸ”´ ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡º' if age_drift > drift_threshold else 'ğŸŸ¢ æ­£å¸¸'}")

    print(f"\n  åå…¥ãƒ‰ãƒªãƒ•ãƒˆï¼ˆæ­£è¦åŒ–ï¼‰: {income_drift:.2f}")
    print(f"    â†’ é–¾å€¤ {drift_threshold} ã¨ã®æ¯”è¼ƒ: {'ğŸ”´ ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡º' if income_drift > drift_threshold else 'ğŸŸ¢ æ­£å¸¸'}")

    # ã‚«ãƒ†ã‚´ãƒªãƒ‰ãƒªãƒ•ãƒˆ
    initial_categories = set(initial_config["categories"])
    drifted_categories = set(drifted_config["categories"])
    new_categories = drifted_categories - initial_categories
    if new_categories:
        print(f"\n  ã‚«ãƒ†ã‚´ãƒª: æ–°ã—ã„ã‚«ãƒ†ã‚´ãƒªè¿½åŠ  {new_categories}")
        print(f"    â†’ ğŸ”´ ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡ºï¼ˆæ–°ã‚«ãƒ†ã‚´ãƒªå‡ºç¾ï¼‰")
    else:
        # åˆ†å¸ƒã®å¤‰åŒ–ã‚’ãƒã‚§ãƒƒã‚¯
        print(f"\n  ã‚«ãƒ†ã‚´ãƒª: åˆ†å¸ƒå¤‰åŒ–ã‚ã‚Š")
        print(f"    â†’ ğŸ”´ ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡ºï¼ˆåˆ†å¸ƒå¤‰åŒ–ï¼‰")

    if args.dry_run:
        print("\nâš ï¸  ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³: ãƒ‡ãƒ¼ã‚¿ã¯æŒ¿å…¥ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
    else:
        # ãƒ‡ãƒ¼ã‚¿ã‚’æŒ¿å…¥
        print("\nğŸ’¾ ãƒ‰ãƒªãƒ•ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’æŒ¿å…¥ä¸­...")
        insert_data(client, project_id, dataset_id, table_id, drifted_df)
        print(f"âœ… {len(drifted_df)} ä»¶ã®ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’æŒ¿å…¥ã—ã¾ã—ãŸ")

        # æŒ¿å…¥å¾Œã®çµ±è¨ˆã‚’å–å¾—
        print("\nğŸ“Š æŒ¿å…¥å¾Œã®çµ±è¨ˆæƒ…å ±ã‚’å–å¾—ä¸­...")
        new_stats = get_existing_stats(client, project_id, dataset_id, table_id)
        new_categories = get_category_distribution(client, project_id, dataset_id, table_id)

        print("\nã€æŒ¿å…¥å¾Œã®ãƒ‡ãƒ¼ã‚¿ï¼ˆå…¨ä½“ï¼‰ã€‘")
        print(f"  ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {int(new_stats['total_records'])}")
        print(f"  å¹´é½¢: å¹³å‡ {new_stats['avg_age']:.1f}, æ¨™æº–åå·® {new_stats['std_age']:.1f}")
        print(f"  åå…¥: å¹³å‡ {new_stats['avg_income']:,.0f}, æ¨™æº–åå·® {new_stats['std_income']:,.0f}")
        print(f"  ã‚«ãƒ†ã‚´ãƒª: {dict(zip(new_categories['category'], new_categories['count']))}")

    print("\n" + "=" * 60)
    print("âœ… ãƒ‰ãƒªãƒ•ãƒˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãŒå®Œäº†ã—ã¾ã—ãŸ")
    print("=" * 60)

    if not args.dry_run:
        print("\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
        print("  1. ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã‚¸ãƒ§ãƒ–ã‚’å®Ÿè¡Œã—ã¦ãƒ‰ãƒªãƒ•ãƒˆã‚’æ¤œå‡º:")
        print("     python monitoring/run_monitor_job.py --wait")
        print("  2. ã‚¸ãƒ§ãƒ–çµæœã‚’ç¢ºèª:")
        print("     python monitoring/list_monitor_jobs.py")


if __name__ == "__main__":
    main()
