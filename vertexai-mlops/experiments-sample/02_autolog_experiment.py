"""
Vertex AI Experiments autolog ã‚µãƒ³ãƒ—ãƒ«

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§ã¯ aiplatform.autolog() ã‚’ä½¿ç”¨ã—ã¦
è‡ªå‹•çš„ã«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨˜éŒ²ã™ã‚‹æ–¹æ³•ã‚’å®Ÿæ¼”ã—ã¾ã™ã€‚

autolog() ã¯ä»¥ä¸‹ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ï¼š
- scikit-learn
- XGBoost
- TensorFlow/Kerasï¼ˆãŸã ã— Keras 3.0 ä»¥é™ã¯éã‚µãƒãƒ¼ãƒˆï¼‰
"""

import os
import yaml
from sklearn.datasets import load_iris, load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from google.cloud import aiplatform

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã® config.yaml ã¸ã®ãƒ‘ã‚¹
CONFIG_PATH = os.path.join(os.path.dirname(__file__), "..", "config.yaml")


def load_config(config_path: str = CONFIG_PATH) -> dict:
    """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
    with open(config_path, "r") as f:
        return yaml.safe_load(f)


def run_sklearn_autolog_example(exp_config: dict):
    """
    scikit-learn ã® autolog ã‚µãƒ³ãƒ—ãƒ«

    autolog() ã‚’æœ‰åŠ¹åŒ–ã™ã‚‹ã¨ã€ä»¥ä¸‹ãŒè‡ªå‹•è¨˜éŒ²ã•ã‚Œã¾ã™ï¼š
    - ãƒ¢ãƒ‡ãƒ«ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆn_estimators, max_depth ç­‰ï¼‰
    - å­¦ç¿’ãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆaccuracy ç­‰ï¼‰
    - ãƒ¢ãƒ‡ãƒ«ã®ã‚¯ãƒ©ã‚¹å
    """
    print("=" * 60)
    print("scikit-learn autolog ã‚µãƒ³ãƒ—ãƒ«")
    print("=" * 60)

    # ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
    iris = load_iris()
    X_train, X_test, y_train, y_test = train_test_split(
        iris.data,
        iris.target,
        test_size=exp_config["data"]["test_size"],
        random_state=exp_config["data"]["random_state"],
    )

    # autolog ã®æœ‰åŠ¹åŒ–ï¼ˆExperiment å†…ã§å®Ÿè¡Œï¼‰
    aiplatform.autolog()

    # è¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«ã‚’è©¦ã™
    models = [
        ("RandomForest", RandomForestClassifier(n_estimators=50, max_depth=5)),
        ("GradientBoosting", GradientBoostingClassifier(n_estimators=50, max_depth=3)),
        ("LogisticRegression", LogisticRegression(max_iter=200)),
    ]

    for model_name, model in models:
        print(f"\nğŸ”„ Training {model_name}...")

        # ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ï¼ˆautolog ã«ã‚ˆã‚Šè‡ªå‹•è¨˜éŒ²ï¼‰
        model.fit(X_train, y_train)

        # ã‚¹ã‚³ã‚¢ã®è¨ˆç®—
        score = model.score(X_test, y_test)
        print(f"   Accuracy: {score:.4f}")

    # autolog ã®ç„¡åŠ¹åŒ–
    aiplatform.autolog(disable=True)

    print("\nâœ… scikit-learn autolog ã‚µãƒ³ãƒ—ãƒ«å®Œäº†")


def run_multiple_experiments_example():
    """
    è¤‡æ•°ã® Experiment Run ã§ autolog ã‚’ä½¿ç”¨ã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«

    ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®ã‚ˆã†ãª
    è¤‡æ•°ã®å®Ÿé¨“ã‚’åŠ¹ç‡çš„ã«è¨˜éŒ²ã§ãã¾ã™ã€‚
    """
    print("\n" + "=" * 60)
    print("ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¢ç´¢ with autolog")
    print("=" * 60)

    # ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
    cancer = load_breast_cancer()
    X_train, X_test, y_train, y_test = train_test_split(
        cancer.data,
        cancer.target,
        test_size=0.2,
        random_state=42,
    )

    # ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®çµ„ã¿åˆã‚ã›
    param_grid = [
        {"n_estimators": 50, "max_depth": 3},
        {"n_estimators": 100, "max_depth": 5},
        {"n_estimators": 100, "max_depth": 10},
        {"n_estimators": 200, "max_depth": 5},
    ]

    best_score = 0
    best_params = None

    for i, params in enumerate(param_grid):
        run_name = f"hp-search-{i+1:03d}"

        with aiplatform.start_run(run=run_name) as run:
            # autolog æœ‰åŠ¹åŒ–
            aiplatform.autolog()

            print(f"\nğŸ”„ Run {run_name}: {params}")

            # ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’
            model = RandomForestClassifier(**params, random_state=42)
            model.fit(X_train, y_train)

            # ã‚¹ã‚³ã‚¢ã®è¨ˆç®—ã¨è¨˜éŒ²
            score = model.score(X_test, y_test)
            run.log_metrics({"test_accuracy": score})

            print(f"   Test Accuracy: {score:.4f}")

            if score > best_score:
                best_score = score
                best_params = params

            # autolog ç„¡åŠ¹åŒ–
            aiplatform.autolog(disable=True)

    print(f"\nğŸ† Best Score: {best_score:.4f}")
    print(f"   Best Params: {best_params}")


def main():
    # è¨­å®šã®èª­ã¿è¾¼ã¿
    config = load_config()
    exp_config = config["experiments"]  # experiments ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’å–å¾—

    # Vertex AI ã®åˆæœŸåŒ–
    aiplatform.init(
        project=config["project_id"],
        location=config["location"],
        experiment=exp_config["name"],
    )

    print(f"Project: {config['project_id']}")
    print(f"Location: {config['location']}")
    print(f"Experiment: {exp_config['name']}")

    # ã‚µãƒ³ãƒ—ãƒ« 1: scikit-learn autolog
    with aiplatform.start_run(run="autolog-sklearn-demo"):
        run_sklearn_autolog_example(exp_config)

    # ã‚µãƒ³ãƒ—ãƒ« 2: è¤‡æ•°ã® Experiment Run
    run_multiple_experiments_example()

    print("\n" + "=" * 60)
    print("âœ… ã™ã¹ã¦ã® autolog ã‚µãƒ³ãƒ—ãƒ«ãŒå®Œäº†ã—ã¾ã—ãŸ")
    print("=" * 60)
    print(
        f"\nConsole URL: https://console.cloud.google.com/vertex-ai/experiments/{exp_config['name']}/runs?project={config['project_id']}"
    )


if __name__ == "__main__":
    main()
