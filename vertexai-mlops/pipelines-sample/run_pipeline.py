#!/usr/bin/env python3
"""
ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè¡Œã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ¸ˆã¿ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ Vertex AI Pipelines ã§å®Ÿè¡Œã—ã¾ã™ã€‚

Requires: Python 3.11+
"""

import argparse
import sys
from pathlib import Path
from typing import Any

import yaml
from google.cloud import aiplatform


def load_config() -> dict[str, Any]:
    """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€ï¼ˆvertexai-mlops/config.yaml ã‹ã‚‰ pipelines ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’å–å¾—ï¼‰"""
    config_path = Path(__file__).parent.parent / "config.yaml"
    with open(config_path, "r", encoding="utf-8") as f:
        root_config = yaml.safe_load(f)

    # pipelines ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’å±•é–‹ã—ã¦ãƒ•ãƒ©ãƒƒãƒˆãªæ§‹é€ ã«å¤‰æ›
    pipelines_config = root_config.get("pipelines", {})
    return {
        "project_id": root_config["project_id"],
        "location": root_config["location"],
        "pipeline": {
            "name": pipelines_config.get("name", "ml-training-pipeline"),
            "pipeline_root": root_config["gcs"]["pipeline_root"],
            "staging_bucket": root_config["gcs"]["staging_bucket"],
        },
        "data": pipelines_config.get("data", {}),
        "training": pipelines_config.get("training", {}),
        "execution": pipelines_config.get("execution", {}),
        "experiments": root_config.get("experiments", {}),
    }


def run_simple_pipeline(
    config: dict[str, Any],
    message: str = "Hello, Vertex AI Pipelines!",
) -> aiplatform.PipelineJob:
    """
    ã‚·ãƒ³ãƒ—ãƒ«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè¡Œã™ã‚‹

    Args:
        config: è¨­å®š
        message: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸

    Returns:
        PipelineJob ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
    """
    template_path = Path(__file__).parent / "compiled" / "simple_pipeline.yaml"

    if not template_path.exists():
        raise FileNotFoundError(
            f"ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ¸ˆã¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {template_path}\n"
            "å…ˆã« python compile_pipeline.py --pipeline simple ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„"
        )

    job = aiplatform.PipelineJob(
        display_name="simple-hello-world-pipeline",
        template_path=str(template_path),
        pipeline_root=config["pipeline"]["pipeline_root"],
        location=config["location"],
        parameter_values={
            "message": message,
        },
        enable_caching=config["execution"]["enable_caching"],
    )

    return job


def run_ml_training_pipeline(
    config: dict[str, Any],
) -> aiplatform.PipelineJob:
    """
    ML ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè¡Œã™ã‚‹

    Args:
        config: è¨­å®š

    Returns:
        PipelineJob ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
    """
    template_path = Path(__file__).parent / "compiled" / "ml_training_pipeline.yaml"

    if not template_path.exists():
        raise FileNotFoundError(
            f"ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ¸ˆã¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {template_path}\n"
            "å…ˆã« python compile_pipeline.py --pipeline ml_training ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„"
        )

    job = aiplatform.PipelineJob(
        display_name=config["pipeline"]["name"],
        template_path=str(template_path),
        pipeline_root=config["pipeline"]["pipeline_root"],
        location=config["location"],
        parameter_values={
            "project_id": config["project_id"],
            "source_table": config["data"]["source_table"],
            "feature_columns": config["data"]["feature_columns"],
            "target_column": config["data"]["target_column"],
            "location": config["location"],
            "test_split_ratio": config["data"]["test_split_ratio"],
            "model_type": config["training"]["model_type"],
            "n_estimators": config["training"]["hyperparameters"]["n_estimators"],
            "max_depth": config["training"]["hyperparameters"]["max_depth"],
            "random_state": config["training"]["hyperparameters"]["random_state"],
        },
        enable_caching=config["execution"]["enable_caching"],
    )

    return job


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    parser = argparse.ArgumentParser(
        description="ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ Vertex AI Pipelines ã§å®Ÿè¡Œã™ã‚‹"
    )
    parser.add_argument(
        "--pipeline",
        type=str,
        default="simple",
        choices=["ml_training", "simple"],
        help="å®Ÿè¡Œã™ã‚‹ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: simpleï¼‰",
    )
    parser.add_argument(
        "--message",
        type=str,
        default="Hello, Vertex AI Pipelines!",
        help="simple ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§ä½¿ç”¨ã™ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸",
    )
    parser.add_argument(
        "--sync",
        action="store_true",
        help="ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å®Œäº†ã‚’å¾…æ©Ÿã™ã‚‹",
    )
    parser.add_argument(
        "--experiment",
        action="store_true",
        help="Vertex AI Experiments ã¨ã®é€£æºã‚’æœ‰åŠ¹ã«ã™ã‚‹",
    )
    parser.add_argument(
        "--no-experiment",
        action="store_true",
        help="Vertex AI Experiments ã¨ã®é€£æºã‚’ç„¡åŠ¹ã«ã™ã‚‹",
    )
    args = parser.parse_args()

    print("=" * 60)
    print("Vertex AI Pipeline å®Ÿè¡Œ")
    print("=" * 60)

    # è¨­å®šã‚’èª­ã¿è¾¼ã‚€
    config = load_config()
    project_id = config["project_id"]
    location = config["location"]

    if project_id == "your-project-id":
        print("âŒ ã‚¨ãƒ©ãƒ¼: vertexai-mlops/config.yaml ã® project_id ã‚’è¨­å®šã—ã¦ãã ã•ã„")
        sys.exit(1)

    # Experiments è¨­å®šã‚’åˆ¤å®š
    experiments_config = config.get("experiments", {})
    if args.experiment:
        use_experiments = True
    elif args.no_experiment:
        use_experiments = False
    else:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ç„¡åŠ¹ï¼ˆ--experiment ãƒ•ãƒ©ã‚°ã§æœ‰åŠ¹åŒ–ï¼‰
        use_experiments = False

    experiment_name = experiments_config.get("pipeline_experiment_name", "ml-training-experiment")

    print(f"\nãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {project_id}")
    print(f"ãƒªãƒ¼ã‚¸ãƒ§ãƒ³: {location}")
    print(f"ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³: {args.pipeline}")
    print(f"Experiments é€£æº: {'æœ‰åŠ¹' if use_experiments else 'ç„¡åŠ¹'}")
    if use_experiments:
        print(f"Experiment å: {experiment_name}")

    # Vertex AI ã‚’åˆæœŸåŒ–
    print("\nğŸ”‘ Vertex AI ã‚’åˆæœŸåŒ–ä¸­...")
    aiplatform.init(
        project=project_id,
        location=location,
        staging_bucket=config["pipeline"]["staging_bucket"],
    )
    print("âœ… åˆæœŸåŒ–ã—ã¾ã—ãŸ")

    # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä½œæˆ
    print("\nğŸ“‹ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚¸ãƒ§ãƒ–ã‚’ä½œæˆä¸­...")
    if args.pipeline == "simple":
        job = run_simple_pipeline(config, args.message)
        job_display_name = "simple-hello-world-pipeline"
    else:
        job = run_ml_training_pipeline(config)
        job_display_name = config["pipeline"]["name"]

    print(f"ã‚¸ãƒ§ãƒ–å: {job_display_name}")

    # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè¡Œ
    print("\nğŸš€ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè¡Œä¸­...")
    service_account = config["execution"].get("service_account") or None

    # Experiments é€£æºã®è¨­å®š
    experiment = None
    if use_experiments:
        print(f"ğŸ§ª Experiment '{experiment_name}' ã«é–¢é€£ä»˜ã‘ã¾ã™...")
        # Experiment ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯è‡ªå‹•ä½œæˆã•ã‚Œã‚‹
        experiment = experiment_name

    job.submit(
        service_account=service_account,
        experiment=experiment,
    )

    print(f"\nâœ… ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’é€ä¿¡ã—ã¾ã—ãŸ")
    print(f"ã‚¸ãƒ§ãƒ–å: {job.display_name}")
    print(f"ãƒªã‚½ãƒ¼ã‚¹å: {job.resource_name}")

    # ã‚³ãƒ³ã‚½ãƒ¼ãƒ« URL ã‚’è¡¨ç¤º
    console_url = (
        f"https://console.cloud.google.com/vertex-ai/pipelines/runs/"
        f"{job.resource_name.split('/')[-1]}?project={project_id}"
    )
    print(f"\nğŸ“Š Cloud Console ã§ç¢ºèª:")
    print(f"   {console_url}")

    if use_experiments:
        experiment_url = (
            f"https://console.cloud.google.com/vertex-ai/experiments/"
            f"{experiment_name}?project={project_id}"
        )
        print(f"\nğŸ§ª Experiment:")
        print(f"   {experiment_url}")

    if args.sync:
        print("\nâ³ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å®Œäº†ã‚’å¾…æ©Ÿä¸­...")
        job.wait()
        print(f"\nâœ… ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãŒå®Œäº†ã—ã¾ã—ãŸ")
        print(f"çŠ¶æ…‹: {job.state}")

    print("\n" + "=" * 60)


if __name__ == "__main__":
    main()
